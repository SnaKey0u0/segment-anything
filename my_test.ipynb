{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam import SamPredictor, sam_model_registry\n",
    "from sam.utils.transforms import ResizeLongestSide\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "image_encoder = sam.image_encoder\n",
    "prompt_encoder = sam.prompt_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "text = clip.tokenize([\"brain\"]).to(device)\n",
    "text_features = clip_model.encode_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    "    SpatialCrop,\n",
    "    AddChanneld,\n",
    "    Transform,\n",
    "    ResizeWithPadOrCropd,\n",
    "    Lambda,\n",
    ")\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    "    DataLoader,\n",
    ")\n",
    "\n",
    "def get_evaluation_transform(spacing):\n",
    "    return Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=None),\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"], a_min=-1024, a_max=3071, b_min=0.0, b_max=255.0, clip=True\n",
    "            ),\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(spacing[0], spacing[1], spacing[2]),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def custom_load_decathlon_datalist(json_data_path, index):\n",
    "    with open(json_data_path, 'r', encoding='utf-8') as json_file:\n",
    "        json_data = json_file.read()\n",
    "    parsed_data = json.loads(json_data)\n",
    "    target = parsed_data[index]\n",
    "    # 路徑+去掉.變成完整路徑\n",
    "    for i in range(len(target)):\n",
    "        target[i]['image'] = data_dir + target[i]['image'][1:]\n",
    "        target[i]['label'] = data_dir + target[i]['label'][1:]\n",
    "\n",
    "    return target\n",
    "\n",
    "# image數量\n",
    "organ_num = {\n",
    "    3:131,\n",
    "    6:63,\n",
    "    7:281,\n",
    "    8:303,\n",
    "    9:41,\n",
    "    10:126,\n",
    "}\n",
    "spacings = {\n",
    "    2: [1.25, 1.25, 1.37],\n",
    "    3: [0.7676, 0.7676, 1],\n",
    "    6: [0.79, 0.79, 1.24],\n",
    "    7: [0.8, 0.8, 2.5],\n",
    "    8: [0.8, 0.8, 1.5],\n",
    "    9: [0.78, 0.78, 1.6],\n",
    "    10: [0.78, 0.78, 3],\n",
    "}\n",
    "data_dir =\"D:\\\\SAM\\\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\med_sam\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_list [{'image': 'D:\\\\SAM\\\\data/imagesTr/liver_14.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_14.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_69.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_69.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_77.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_77.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_120.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_120.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_18.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_18.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_65.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_65.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_30.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_30.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_37.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_37.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_29.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_29.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_54.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_54.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_103.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_103.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_25.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_25.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_58.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_58.nii.gz'}, {'image': 'D:\\\\SAM\\\\data/imagesTr/liver_46.nii.gz', 'label': 'D:\\\\SAM\\\\data/labelsTr/liver_46.nii.gz'}] 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 14/14 [01:05<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 457, 457, 588])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 503, 503, 489])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 521, 521, 466])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 496, 496, 636])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 615, 615, 676])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 417, 417, 410])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([1, 667, 667, 200])\n",
      "<class 'monai.data.meta_tensor.MetaTensor'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "task_list = [3,6,7,8,9,10] #3,6,7,8,9,10\n",
    "for task in task_list:\n",
    "    datasets = os.path.join(data_dir, f\"dataset_{task}.json\")\n",
    "\n",
    "    # 得到data path list\n",
    "    datalist = custom_load_decathlon_datalist(datasets, \"training\")\n",
    "\n",
    "    split_index = organ_num[task]* 4 // 5\n",
    "    segment1 = datalist[0:7]\n",
    "    segment2 = datalist[split_index:min(split_index+7, organ_num[task])]\n",
    "    # 连接两个段\n",
    "    eval_list = segment1 + segment2\n",
    "    print('eval_list', eval_list, len(eval_list))\n",
    "\n",
    "    dataset = CacheDataset(\n",
    "        data = eval_list,\n",
    "        transform = get_evaluation_transform(spacings[task]),\n",
    "        cache_num = 24,\n",
    "        cache_rate = 1.0,\n",
    "        num_workers = 8,\n",
    "    )   \n",
    "\n",
    "    # split_index = len(datalist) * 4 // 5\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image, label = dataset[i]['image'], dataset[i]['label']\n",
    "        \n",
    "        # 獲取圖像和標籤的形狀\n",
    "        print(image.shape)\n",
    "        _, D, H, W = image.shape\n",
    "        print(type(image))\n",
    "        \n",
    "        # 遍歷每一個slice\n",
    "        for d in range(D):\n",
    "            # 獲取2D slice\n",
    "            image_slice = image[0, d, :, :]\n",
    "            label_slice = label[0, d, :, :]\n",
    "            image_slice_uint8 = image_slice.astype(np.uint8)\n",
    "            # 顯示圖像\n",
    "            cv2.imshow('Image Slice', image_slice_uint8)\n",
    "            cv2.imshow('Label Slice', label_slice.cpu().numpy())\n",
    "            \n",
    "            # 等待並檢查是否有按鍵事件\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            \n",
    "            # 如果按下 'q' 鍵，則退出循環\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        # 如果按下 'q' 鍵，則退出循環\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "            \n",
    "            # if not os.path.exists(f\"my_data/task{task}\"):\n",
    "            #     os.makedirs(f\"my_data/task{task}\")\n",
    "            # # 保存為.npy文件\n",
    "            # np.save(f'my_data/task{task}/image_{i}_{d}.npy', image_slice.cpu().numpy())\n",
    "            # np.save(f'my_data/task{task}/label_{i}_{d}.npy', label_slice.cpu().numpy())\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
